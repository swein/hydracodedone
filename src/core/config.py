from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import Optional
import os


class Settings(BaseSettings):
    # To load from .env file, ensure python-dotenv is installed
    # and pydantic_settings will automatically load it.
    model_config = SettingsConfigDict(
        env_file=".env", env_file_encoding="utf-8", extra="ignore"
    )

    OPENAI_BASE_URL: str = "http://127.0.0.1:1234"
    OPENAI_CRITIQUE_BASE_URL: Optional[str] = (
        None  # Optional separate URL for critique model
    )
    PRIMARY_MODEL_NAME: str = "mistralai/magistral-small-2509"  # Default primary model

    def _adjust_for_docker(self, base_url: str) -> str:
        """
        Helper method to adjust URL for Docker container networking.
        If we're running in Docker and the URL uses localhost/127.0.0.1,
        we need to use host.docker.internal to reach the host machine.
        If we're using host networking, keep localhost/127.0.0.1 as-is.
        """
        base_url = base_url.rstrip("/")

        # Check if we're in a Docker container
        in_docker = os.path.exists("/.dockerenv")

        # Check if we're using host networking (by checking if we can resolve localhost to 127.0.0.1)
        using_host_network = False
        if in_docker:
            try:
                import socket

                # If localhost resolves to 127.0.0.1, we're likely using host networking
                localhost_ip = socket.gethostbyname("localhost")
                using_host_network = localhost_ip == "127.0.0.1"
            except Exception:
                pass

        if (
            in_docker
            and not using_host_network
            and ("localhost" in base_url or "127.0.0.1" in base_url)
        ):
            # Replace localhost/127.0.0.1 with host.docker.internal for Docker containers
            if "localhost" in base_url:
                return base_url.replace("localhost", "host.docker.internal")
            elif "127.0.0.1" in base_url:
                return base_url.replace("127.0.0.1", "host.docker.internal")

        return base_url

    @property
    def effective_openai_base_url(self) -> str:
        """
        Get the effective OpenAI Base URL for primary model, adjusting for Docker container networking.
        """
        return self._adjust_for_docker(self.OPENAI_BASE_URL)

    @property
    def effective_critique_base_url(self) -> str:
        """
        Get the effective OpenAI Base URL for critique model, adjusting for Docker container networking.
        Falls back to primary base URL if critique URL is not configured.
        """
        if self.OPENAI_CRITIQUE_BASE_URL:
            return self._adjust_for_docker(self.OPENAI_CRITIQUE_BASE_URL)
        return self.effective_openai_base_url

    # Future settings for Model 2 (Critique Model)
    CRITIQUE_MODEL_NAME: Optional[str] = (
        "mistralai/magistral-small-2509"  # Default critique model, can be same or different
    )
    CRITIQUE_SYSTEM_PROMPT: Optional[
        str
    ] = (  # Default system prompt for critique model
        "You are an expert critique and refinement AI. "
        "Your task is to improve a response generated by another AI assistant (Model 1) for a given user query.\n\n"
        "The original user query was:\n"
        "---USER QUERY START---\n"
        "{original_user_query}\n"
        "---USER QUERY END---\n\n"
        "Model 1 (the initial assistant) provided the following response:\n"
        "---MODEL 1 RESPONSE START---\n"
        "{model_1_response_content}\n"
        "---MODEL 1 RESPONSE END---\n\n"
        "Critique Model 1's response based on accuracy, completeness, clarity, conciseness, and adherence to best practices (especially if it's code). "
        "Then, generate a new, improved response that directly answers the original user query, addressing any flaws you found. "
        "Your output should ONLY be the refined response, suitable to be sent back to the user as if you were the primary assistant. "
        "Do NOT include any preamble like 'Here is the refined response:'."
    )

    # Logging level, e.g., INFO, DEBUG
    LOG_LEVEL: str = "INFO"


settings = Settings()
